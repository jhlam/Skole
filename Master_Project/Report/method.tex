\chapter{Method} \label{methode}
In this chapter, we will discuss how we designed the high level system and how the different core is connected. We will in later chapter discuss the choice of said designs. For this project, we have implemented a simple Linear-feedback Shift Register(LFSR) and our custom IP core which for this report will be called Data Diffusion Core(DD Core).


The LFSR is a commonly used random number generator(RNG)[CITATION NEEDED]. Different sized LFRS is able to generate pseudo random numbers dependent on how large the LFSR is. LFSR generates a pseudorandom number based on the previous number. The LFSR is a register containing 16 bit. we take the bit from, 16,14,13 and 11, resulting in (((16 XOR 14) XOR 13 ) XOR 11) = bit. The bit is pushed into bit-position 1 and the entire raegisters shifts towards left 1 bit. 

We ran multiple test to prove that the LFSR is determenistic. As we can see from the table below:

[INSERT TABLE; 2 COL: both send in the same seed and we can see that we receive same number,](Can look at the master thesis Donn send me ages ago.)

The IP core we created, Takes in different signals, The address to the location to the matrix, the location to the result, and the x-buffer. Since we are working with ICM, a global probability, a random seed as the initial state for the LFSR. The core applies matrix vecotr mulitplication. For this implementation, a vector, vector multiplication is applied, to be able to handle graph that is larger then recomended cache size. The cache have not enough space to store the entire adjacency matrix. 

We started by creating the pseudocode to our implementation. The code was a modified form of the shown code of sparse matrix vector multiplication over a boolean semiring.

For this project, we created a sparse matrix with a R-mat generator. The R-mat generator is an simple python program that creates a sparse matrix with total elements equal = power(2,n). The amount of edges that was created is (total_amount_of_edge \times edgefactor). The matrix is stored as a single text file that contains a string containing 1s or 0s. The R-mat generator partitions the matrix into different parts where the element is placed. Each part have a specific percentage. A=0.57, B=0.19, C=0.19, D=0.05. For a undirected adjacency matrix, The matrix must be diagonally identical. [POST PSEUDOCODE OF GENERATOR?]

For our core, we used the architecture of memory mapped. We pass the address in the form of AXI4-lite. The core includes an dma-function, which the HLS have included for us.

We implemented a vector-vector multiplication. The multiplications applies the logical action AND with each element in the vector with the corresponding element in the row of the matrix. 




- Start by creating pseudocode to illustrate how the Independent cascade model works and how to set up the code.
- Implement the algorithm(ICM) in C code, since High level synthesis synthesis C/C++ code. 
- Create test to make sure the code is correct. (Test early to catch problem early.)
- Port the code over to be high level synthesis compatiable. () 
- analyse the implementation.
- implement on Hardware.
- might want to implement wiwth interface, AXI 4 and stuff like that 


NOTES: 
For our example, a AXI4 Stream would be best i think.

implemented a 16-bit LFSR(linear feedback shift register) to generate the random number, which is used to calculate if the activation will take place.
each have a [5-25\%] activation rate. implemented some different models, use a array instead of a matrix. 

WE have created a generator following the R-mat generator for sparse graph for testing.
We implemented the simulation as a sparse matrix vector multiplication
we implemented that in vivado HLS. and synthesised it
We changed the implementation to accomodate the requirements for HLS; - no recursion, unknown matrix length and allocation of memory. 



pseudocode section:
matrix_vector_multiplication(matrix, x\_vector, result\_vector, coin\_toss, total_node):

	for(row->total_node) do:
		for(col -> total_node) do:
			if(x_vector[col] && matrix[row][col]) do:
				if(row=col) do :
					local\_result = 1;
				else do:
					local\_result = coin\_toss && local_result;
		}	
		result[row] = local\_result;
		local\_result = 0;................


\section{Parallization}
The function matrix\_vector\_multiplication() performes a single matrix vector multiplication. From the pseudocode, we can see that there is a room for parallization of the SPmV. The outer for loop from the pseudocode, can be parlized since thatfoor loop is not dependent on the variable from the inner for-loop. 

another paralization is during the simulation, after the spmv, the frontier needs to be calculated. And a converged() function is called in the end to determen if the simulation is finished. The frontier calculation and converged can pe run in parallel. 

THe IP-core (currently) is only using around 2\% of the resource available on the FPGA(Zedboard). This gives us a lot of room for parallization of different core. Implemented 2 bus, one for input stream, one for output stream. The output stream consist of the result_vector

THe input vector is the seed_vector and the matrix. The seed and the global probability is used a AXI4 lite since they only read once, 


IP Core Structure:
For the second option, where the RNG core is not implemented into the IP CORE, we would have to have teh random number set as AXI4 stream from the buffer, since we would need to call a stream of random number from the core.


(global vs local probability)
For this experiment, we have set a standard global probability, that signef that each activation of nodes is at a specific probability. THe local probability is that there are a loccal probability to each edge. Each edge can have a specific probability.


\section{High Level Synthesis}
HLS have many predefined protocol, axi4lite, srteam etc etc. These can be implemented in vivado HLS easily. The program needs to be predefined so that it knows when the streaming is done. The axi stream is best suited for stream of data. The work flow to the HLS is to first generate the C or C++ code. Then the create a testbench. then run the co-simulation. The co-simulation runs the test on both on the C-code and the simulated core. After that, run the core to the vivado to implement and design the core. 