\chapter{Related Work}  \label{relatedWork}


Here, we will give you a short overview of the current state regarding Information Diffusion, High Level Synthesis and different optimization options.

\begin{itemize}
  
\item Yamans paper, where there are some works that shows the solution i use
\item parallalization of the algorithm
\item maybe some examples of HLS to show that HLS is used.
\item showe that there are not many HLS implementation, recently matured. 
\item show that there are not many hardware implementation for information diffusion.
\item need to look through Yamans paper and get some refrences from there.
\item might be good to look at how this type of sparce matrix multiplication can be used
\item show other implementation of SPmv
\item Show some examples where image processing is done through vivado HLS.
\item \cite{HLSTutorial} A good paper showing the state of the art for HLS.

\end{itemize}

This chapter, we will look at the state of research regarding High Level Synthesis, network research regarding Information Diffusion, and Optimization of Independent cascade model and Breadth first search.

\section{Information Diffusion} 
There are multiple studies done regarding Information Diffusion. One studies shows how information diffusion can be applied during an disease outbreak\cite{InformationDiffusionThroughBlogspace}, viral marketing\cite{ViralMarketing}, coordinat during crisis situation\cite{Starbird:2012:RRI:2145204.2145212}. 

Models of influence have been done on blogs\citep{Adar:2005:TIE:1092358.1092473}\cite{GomezRodriguez:2010:IND:1835804.1835933}, and twitter\cite{Bakshy:2011:EIQ:1935826.1935845}. We can see that in an age of social media, the studies of information diffusion is more relevant then ever. 

while other\cite{InfoDiffAndExternalInfluInNetworks} have argued that the emerging of social network and media, have changed the traditional model. The activation is no longer only relying on neighbour nodes, but also an external influence. They found that large amount of  information volume in Twitter is the result of network diffusion, while a small amount is due to external events and factors outside the network\citep{InfoDiffAndExternalInfluInNetworks}. Another studies shows during the 2011 Egyptian Uprising, how larg amount of such a movement were "tweeted"\cite{Starbird:2012:RRI:2145204.2145212}.


As we mentioned in chapter \ref{background}, we mainly focus on 2 common information diffusion models, ICM and LTM. But there are different models too. One report\cite{5694014} proposed several different problems with traditional models where each node is either \textit{activated}(infected, influenced, '1') or \textit{inactive}(healthy, not reached, '0'), and passes the \textit{contagion}(information, data, infection, influence) to a neighbouring nodes through the edges. The report mentioned different assumptions that such models take. Among them is that a complete graph is provided, the spread of contagion is from a known source, and that the structure in the network is sufficient to explain the the behaviour\citep{5694014}. The report propose an alternative model, \textit{Linear Influence Model}(LIM), where the focus is on the global influence a infected node has on the rate of diffusion through the implicit network. This model takes the assumptions, that newly activated nodes is dependent on previous activated nodes. The LIM does not need explicit knowledge of the entire network, instead the model takes the newly activated nodes and model them as a \textit{influence function}, which is used to find the global influence. 	



\section{High Level Synthesis}
High Level Synthesis as a concept have been around since the mid-1980s and early-1990s. Early tools, known as Carnegie-Mellon University design automation (CMU-DA)\citep{1085036}\citep{Parker:1979:CDA:800292.811694} was a pioneering early version of HLS tool. The tool gathered quickly considerable interest. A number of HLS tools were built in later year mostly for prototyping and research\cite{Granacki:1985:AAD:317825.317970}\citep{Paulin:1986:HMA:318013.318055}\citep{4069894}. Some of these early tools was able to produce real chips, but the reason for lack of further development and adaptation, was that RTL synthesis was not a widely accepted and immature field. This often lead to suboptimal solutions. 

In the 2000, new HLS tools was developed in academia and in the industry. These tools, used hihg level language, C and C++. Vivado HLS, designed by Xilinx \citep{6409453}, is one such HLS tool. The Vivado HLS became free during their 2015.4 update\citep{VIVADOHLS}. This resulted in an revived interest in HLS. The community around HLS is also evolving, on the Xilinx-forum, there are multiple anwsers and active members. We can see that the solution designed by HLS tools is close to traditional hand-crafted designs\citep{6718388}.

\subsection{Different HLS implementations}
in \citep{Malazgirt:2015:HLS:2889287.2889299}, HLS was used to design an accelerator for database analytic and SQL operation. The design was implemented on a Virtex-7 xc7vx690t-g1761-2 FPGA with focus on accelerating operations as join, data filter, sort, merge and string matching. The accelerator was implemented in C++ in Vivado HLS and optimized with UNROLL directive, PIPELINE directive and ARRAY\_PARTITION. The UNROLL directive unroll all of the specified loops, while the PIPELINE directive allows multiple accelerator to process data at each clock cycle. The ARRAY\_PARTITION directive partition data into registers.  The accelerator showed promises, giving a 15-140$\times$ speedup compared to Postgres software DBMS running selected TPC\-H queries. 

\cite{Bailey:2015:ALH:2789116.2789145} explored the advanteage and disadvanteges of HLS implementation of image processing. Here, they argued that, most often, custom algorithm on FPGA platform will result in an improvement, but simply porting an existing algotrithm might not be a improvement. Here, the author conducted different case studies to show both the strength and the weakness with HLS. The report goes through image filtering, connected component analysis and two dimensional FFT. One example that the authore brings up, is during image filtering. The HLS was not able to identify the standard accessing pattern during special cases and resulted in that the HLS built additional hardware to counter such a exception. The report conclude with that while HLS can significantly reduce development time and improve utilization of design space, it is still important to focus on careful design. 
By recompiling the algorithm in HLS would result in an suboptimal solution, the designers would need to customize the algorithm for the HLS to optimize for FPGA implementation. The report concludes that HLS can offer many benefits, and is an improvement over conventional RTL-designs, but is not an replacement for hardware designers or clever designs. 

\cite{Butt:2016:DPH:2888407.2871737} implemented an fast Fourier transform (FFT) algorithm for different digital system processing application in HLS. There teh authors used Simulink for vcerification of design, and implemented it in HLS.

\cite{Zuo:2013:IHL:2435264.2435271} discuss improvements to the current HLS tools with  polyhedral transformation. Here they discuss a problem with HLS, which is that unless the code is inherently compatible, HLS can't apply most of the optimizations. Zuo et al. proposed the polyhedral model, the model takes data/dependent multi-block program as input and performes 3 steps: Classification of array access pattern, performance Metric, and implementation. During the classification of array access pattern, a set of data access pattern is defined and classified, then the appropiate loop transformation is applied. The next step, the performance of each loop transformation with data-dependency is estimated, and the best improvement is chosen. The last step, the chosen solution, loop transformation and inserting HLS directive is applied. Then a interface block for the data-dependent blocks is generated. The generated communicatiion block is then optimized depending on how it behaves. The paper concludes with that the poluhedral model can model can find important loop transformation, thus enable optimization such as pipeline and parallelization.

\section{Different optimization scheme}

 